# Team-Info
| (1) 과제명 | 외국인 한국어 학습자를 위한 음성 인식 기반 발음 교정 및 회화 연습 서비스
|:---  |---  |
| (2) 팀 번호 / 팀 이름 | 26-Joggim' |
| (3) 팀 구성원 | 조하은 (2271058): 리더, 백엔드 개발 <br> 김민지 (2271013): 팀원, 프론트엔드 개발, gpt 프롬프팅 <br> 김서윤 (2271014) : 팀원, AI 개발			 |
| (4) 팀 지도교수 | 심재형 교수님 |
| (5) 과제 분류 | 산학 과제 |
| (6) 과제 키워드 | 음성 인식, STT, 인공지능, 교육  |
| (7) 과제 내용 요약 | K-Talk은 외국인을 대상으로 한 한국어 학습 서비스로, 음성 인식 기술을 활용하여 사용자가 한국어 발음을 연습하고 피드백을 받을 수 있도록 돕습니다. 사용자는 음성 입력을 통해 문장을 발음하고, 시스템은 그 발음을 분석하여 피드백을 제공하며, 개인화된 학습 경로를 통해 점진적으로 한국어 실력을 향상시킬 수 있습니다. 이 서비스는 한국어 학습을 보다 효과적으로 지원하기 위해 다양한 음성 인식 및 TTS(Text-to-Speech) 기술을 활용합니다. |

<br>

# Project-Summary
| 항목 | 내용 |
|:---  |---  |
| (1) 문제 정의 | 한국에 거주하는 외국인은 2025년 기준 265만 명 이상이며, 이들 중 많은 수가 한국어 발음 문제로 인해 실질적인 의사소통의 어려움을 겪고 있음. <br> 한국어의 연음·된소리·받침 발음 등은 비원어민에게 익숙하지 않아, 발음 오류가 의미 전달 실패, 소통 단절, 자신감 저하로 이어짐. <br> 현재 한국어 교육은 문법·어휘 중심으로 구성되어 있어, 실시간 피드백을 통한 발음 교정이 어려움.  <br> <br> 🎯 Target Customer <br> •	한국에 거주 중인 외국인 학습자	<br> •	실생활에서 원활한 의사소통이 필요한 직장인, 유학생 등 <br> <br> 🔥 Pain Points	<br> •	발음 오류로 인한 의미 전달 실패	<br> •	소통 불편 → 사회·직장 내 적응 어려움 <br> •	현재 서비스는 발음 피드백이나 교정 기능이 부족함	<br> •	어떤 발음을 틀렸는지 스스로 알기 어려움|
| (2) 기존연구와의 비교 | *유사한 과제/연구/서비스/시스템의 예를 들고, 각각의 장단점을 기술할 것. 특히, 본 과제가 유사과제에 대하여 갖는 장점을 부각할 것* |
| (3) 제안 내용 | *본 프로젝트에서 제시한 문제를 해결하기 위해 새롭제 제안하는 해결책 or 해결책들에 대하여 기술 .* |
| (4) 기대효과 및 의의 | *프로젝트의 결과물을 통하여 얻을 수 있는 기대효과 및 의의에 대하여 기술 .*	<br>•	정확한 한국어 발음 습득을 통해 외국인의 사회 적응력 강화 <br>	•	실생활·직장 내 커뮤니케이션 능력 향상 <br>	•	개별 발음 패턴을 분석한 맞춤형 학습 제공으로 학습 효율 극대화 <br>	•	AI 기반 발음 교정 기술을 활용한 차세대 한국어 학습 서비스 모델 제시 |
| (5) 주요 기능 리스트 | *(3)에서 제안한 해결책들을 지원or구현하기 위하여 필요한 주요 기능 혹은 기능을을 List-up하고, <br> 각각에 대하여 설명* <br> * 본 항목의 내용을 충실히 기재 바람니다. <br>1. 발음 분석 및 피드백 : Whisper API를 활용하여 발음을 텍스트로 변환하고, 모범 발음과 비교하여 오류를 시각적으로 피드백 <br>2. 음성합성(TTS) : Glow-TTS를 활용해 학습자가 정확한 발음을 들으며 따라할 수 있도록 모범 발음 제공 <br> 3. GPT 기반 문장 교정 및 대화 연습 : 실전 대화 연습을 통해 문법, 표현 오류를 잡아주고 자연스러운 표현을 학습하도록 지원 <br> 4. 개인 맞춤형 학습 경로 추천 : 사용자의 발음 패턴을 분석하여 개선이 필요한 음소/문장을 기반으로 학습 문장 추천 *|

<br>
 
# Project-Design & Implementation
| 항목 | 내용 |
|:---  |---  |
| (1) 요구사항 정의 | *프로젝트를 완성하기 위해 필요한 요구사항을 설명하기에 가장 적합한 방법을 선택하여 기술* <br> 예) <br> - 기능별 상세 요구사항(또는 유스케이스) <br> - 설계 모델(클래스 다이어그램, 클래스 및 모듈 명세서) <br> - UI 분석/설계 모델 <br><br>**<DB 설계 모델>** <br> ![ER 다이어그램](https://github.com/user-attachments/assets/823138d9-9707-417c-92d6-ef1407cb22b1)<br>- **`User`:** 사용자 정보 저장<br>- **`Topic`:** 사용자가 학습할 주제 저장<br>- **`Sentence`:** 사용자가 학습할 문장을 저장<br>- **`LearningHistory`:** 사용자가 학습한 문장의 통과 여부, 오류 내역을 저장<br>- **`ChatRoom`:** 사용자와 챗봇 간의 채팅방을 저장<br>- **`UserMessage`:** 사용자가 챗봇에게 보낸 메시지를 저장<br>- **`BotMessage`:** 챗봇이 응답한 메시지를 저장<br>- **`GrammarFeedback`:** UserMessage에 문법 오류가 있다면 문법 교정 피드백 제공<br>- **`PronunciationFeedback`:** UserMessage에 발음 오류가 있다면 발음 교정 피드백 제공<br>- **`TokenBlacklist`:** 로그아웃된 JWT 토큰을 저장하여 인증을 차단|
| (2) 전체 시스템 구성 | ![시스템 구조도](https://github.com/user-attachments/assets/6cd9944b-66c8-4886-b6a8-40752aa0a9e1)<br>**프론트엔드**<br>- React: 사용자 인터페이스 제공, 음성 녹음 및 전송<br><br>**백엔드**<br>- Spring Boot: 사용자 관리, 학습 데이터 제공, API 통합<br>- AWS EC2, Docker: 서버 배포 및 관리<br><br>**데이터베이스**<br>- MySQL: 서비스 관련 데이터 저장<br>- AWS RDS: MySQL 데이터베이스 관리<br>- Firebase: 음성 파일 저장<br><br>**AI**<br>- Flask: AI 서버 실행<br>- Whisper: 사용자의 음성을 텍스트로 변환 (STT)<br>- Glow-TTS: 학습을 위한 한국어 발음 생성 (TTS)<br>- OpenAI API: 사용자의 발음 및 문장에 대한 GPT 기반 피드백 제공 |
| (3) 주요엔진 및 기능 설계 | **1. 클라이언트: `React`**<br>- 대화 연습 화면, 음성 녹음 및 학습 화면 등 UI를 제공하여 학습자와 시스템 간의 상호작용<br>- 음성 녹음 기능을 제공하여 사용자가 발음을 입력하고 이를 서버로 전송<br>- RESTful API를 통해 백엔드와 실시간으로 통신하여 사용자 데이터를 관리하고, 학습 피드백을 실시간으로 제공<br><br>**2. 서버: `Spring Boot`**<br>- 사용자 관리, 학습 데이터 제공, 채팅 관리 등<br>- AI 모듈과 연결하여  발음 분석 및 교정, 음성 합성 요청 등을 처리<br>- AWS EC2 인스턴스를 이용하여 Docker를 통해 환경을 컨테이너화하여 배포 및 관리<br><br>**3. AI 모듈**<br>- **`Flask`**: 백엔드 서버 와 연결되어 API 요청을 처리하고, 각 AI 엔진에 맞는 입력값을 전달하여 처리된 결과를 다시 백엔드로 반환<br>- **`Whisper`**: Whisper는 음성 인식 모델로, 사용자의 음성을 텍스트로 변환. 텍스트로 변환된 음성은 원본 문장과 비교하여 피드백 제공에 사용<br>- **`Glow-TTS`**: 텍스트를 음성으로 변환하여 학습자가 문장을 정확하게 발음할 수 있도록 모범 발음을 제공<br>- **`GPT`**: 사용자가 입력한 문장에 대해 문법 오류를 수정하거나 표현을 개선하는 피드백을 제공<br><br>**4. 데이터베이스**<br>- **`MySQL`**: 사용자 정보, 학습 기록, 문장 데이터 등을 저장<br>- **`AWS RDS`**: 백업, 자동 확장성, 보안 등의 기능을 제공하여 데이터의 안정성과 관리 효율성을 높임<br>- **`Firebase`**: 사용자가 업로드한 음성 데이터를 저장하고 관리<br><br>**5. 음성 인식 엔진**<br>- 사용자의 발음을 텍스트로 변환<br>- 변환된 텍스트와 원본 문장을 비교하여 오류 분석<br>- 구현 방식:<br>    - React에서 녹음된 음성을 파일로 변환<br>    - 백엔드를 통해 AI 서버로 전송 <br>    - AI 서버에서 Whisper API 호출하여 STT 변환<br>    - 변환된 텍스트를 분석 후 피드백 반환<br><br>**6. 음성 합성 엔진**<br>- 사용자가 정확한 발음을 들으며 연습할 수 있도록 음성 제공<br>- 사용자가 특정 문장을 요청하면 Flask 서버에서 Glow-TTS를 호출하여 음성 파일 생성
- 생성된 음성을 백엔드로 전송 후 프론트엔드에서 재생<br><br>**7. 챗봇 엔진**<br>- GPT 기반의 챗봇을 구현하여 사용자의 문법 및 표현 오류를 실시간으로 피드백<br>- 사용자가 말한 문장을 분석하여 문법 및 표현 오류 수정<br>- 보다 자연스러운 표현을 제공하고 대화를 제공하여 사용자에게 한국어 회화 연습 제공<br>- 구현 방식:<br>    - STT 변환된 텍스트를 GPT 모델에 전달하여 문장 교정 요청<br>    - 수정된 문장 및 피드백을 사용자에게 제공 |
| (4) 주요 기능의 구현 | *<주요기능리스트>에 정의된 기능 중 최소 2개 이상에 대한 상세 구현내용을 기술한다.* |
| (5) 기타 | *기타 사항을 기술*  |

<br>
